## Internal Model Representation

The internal model is stored in a JSON format and depending on the machine learning framework, it is generated by ``import_json.py``, ``import_prototxt.py``, or ``import_graphdef.py``. The following documentation is based on logging the model format from these files.

### Format of Model
The model is stored under the ``"net"`` key in the dictionary, with each layer as a new sub-dictionary. Within each layer, under the layer name, there are three keys: info, connection, and params. Here is a sample format:
```sh
{"net":
    {layer_name1:
        {"info":{}, 
        "connection":{}, 
        "params":{}
    }, 
    {layer_name2:
        {"info":{}, 
        "connection":{}, 
        "params":{}
    }
}
```
### More Detail about Layer Format

Here is more information about the ``"info"``, "connection", and ``"params"`` parts of the layer.
##### ``"Info"`` Section
Under the ``"info"`` section these are the two stored variables: ``"type"``, and ``"phase"``. ``"Type"`` indicates the category of layer. Here are the most common categories:
* ``Input``
* ``Data``
* ``Dense``
* ``Activation``
* ``Dropout``
* ``Flatten``
* ``Reshape``
* ``Convolution``
* ``Upsample``
* ``Padding``
* ``Pooling``
* ``LocallyConnected``
* `` Recurrent``
* ``Embed``

"Phase" by default is ``null``. It may be different if the layer changes depending on whether it is being used for training or testing.

Here is an example:
```sh
{"info": {"phase": null, "type": "Pooling"}
```
##### ``"Connection"`` Section
Under the ``"info"`` section these are the two stored variables: ``"input"``, and ``"output"``. Since the model is not stored in order of layers, the names of the input and output layers are used to sort the model(ie. matching the output name of one layer to the input name of another layer).

Under ``"input"``, the name of the layer that feeds into the current layer is stored. This means for the first layer(input layer), this section is empty.

Similarly, under ``"output"``, the name of the layer that the current layer feeds into is named. This means that for the final layer, this section will be left empty.

Here is an example:
```sh
"connection": {"input": ["embedding_1_input"], "output": ["dropout_1"]}
```
##### ``"Params"`` Section
* In this section, depending on the type of layer, the criteria are different. There are several different params(for configuring each layer) but here are the some common params to get a sense:

* ``"layer_type"`` - ``"1D"``, ``"2D"``, or ``"3D"``
* ``"stride_w"``, ``"stride_l"``, ``"stride_h"``
* ``"kernel_w"``, ``"kernel_l"``, ``"kernel_h"``
* ``"pad_w"``, ``"pad_l"``, ``"pad_h"``
* ``"num_output"``
* ``"weight_filler"``
* ``"use_bias"``
* ``"pool"``

Here is an example:
```sh
"params": {
    "layer_type": "2D", 
    "kernel_w": 2, 
    "pad_h": 0, 
    "stride_h": 2, 
    "stride_w": 2, 
    "kernel_h": 2, 
    "pad_w": 0, 
    "pool": "MAX"}
```

 ### Example JSON Model File: 
* [AllCNN.json](https://github.com/rpalakkal/Fabrik/blob/rpalakkal-internalModel/sample/internalModels/allCNN.json)
* [LeNet.json](https://github.com/rpalakkal/Fabrik/blob/rpalakkal-internalModel/sample/internalModels/lenet.json)
* [Cifar10CNN](https://github.com/rpalakkal/Fabrik/blob/rpalakkal-internalModel/sample/internalModels/cifar10cnn.json)

